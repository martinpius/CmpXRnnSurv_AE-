# -*- coding: utf-8 -*-
"""RNN_COMPLEX_SURV_LIGHTNING.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zVXdKZHr5chXk0_TZ0_xUJKb9mzPqLm-
"""

# The RNN for Complex Survival Problems with Pytorch Lightning. The Main Model Class

# Commented out IPython magic to ensure Python compatibility.
# %%capture
# !pip install pytorch-Lightning

from torch import nn, optim
import torch.nn.functional as F
import pytorch_lightning as pl
import numpy as np
import torch

from argparse import ArgumentTypeError
class Encoder_RNN4Surv(pl.LightningModule):
  '''
  @Author: Martin Pius
  -The main rnn-module to be integrated with Lightning Module
  '''
  def __init__(self,
               input_dim,
               hidden_dim, 
               num_layers, 
               seq_len,
               rnn_type,
               bidirectional = True):
    super(Encoder_RNN4Surv, self).__init__()
    #self.num_numerical_features = num_numerical_features
    #self.categorical_nunique_to_dims = categorical_nunique_to_dims
    #self.fc_layers_construction = fc_layers_construction
    #rnn_input = Features_Prep(categorical_nunique_to_dims, num_numerical_features, fc_layers_construction, dropout)
    self.hidden_dim = hidden_dim
    self.num_layers = num_layers
    self.rnn_type = rnn_type
    self.seq_len = seq_len
    self.bidirectional = bidirectional
    self.rnn = nn.RNN(input_size = input_dim, hidden_size = self.hidden_dim,
                      num_layers = self.num_layers, dropout = 0.25, 
                      bidirectional = self.bidirectional)

    self.lstm = nn.LSTM(input_size = input_dim, hidden_size = self.hidden_dim,
                        num_layers = self.num_layers, dropout = 0.25,
                       bidirectional = self.bidirectional)
    self.gru = nn.GRU(input_size = input_dim, hidden_size = self.hidden_dim,
                      num_layers = self.num_layers,
                      bidirectional = self.bidirectional, dropout = 0.25)
    if self.bidirectional:
      self.fc = nn.Linear(2 * self.hidden_dim, self.hidden_dim)
    else:
      self.fc = nn.Linear(self.hidden_dim * self.num_layers, self.hidden_dim)
    
  def forward(self, rnn_input):
    """
    rnn_input: Call from the Prep_class: shape == [batch_size, input_dim]
    ### must be reshaped to [seq_len, batch_size, input_dim] ###
    rnn_output: shape if BRNN == [seq_len, batch_size, 2* hidden_dim], else: [seq_len, batch_size, hidden_dim] 
    rnn_hidden_state: shape if BRNN = [num_layers*2, batch_size, hidden_dim] else: [num_layers, batch_size, hidden_dim]
    lstm_cell_state: shape if BRNN = [num_layers*2, batch_size, hidden_dim] else: [num_layers, batch_size, hidden_dim]
    hidden[-1,:,:] = is the last of the backward rnn if BRNN
    enc_hidden[-2,:,:] = is the last of the forward rnn if BRNN
    ## We need to stack backward and forward rnn hidden results incase of BRNN ##
    """
    # reshape the input to have the shape of [seq_len, batch_size, input_dim]
    x = rnn_input.unsqueeze(0).repeat(self.seq_len, 1, 1) # shape == [seq_len, batch_size, input_dim]
    if self.bidirectional:
      if self.rnn_type == "RNN":
        h0 = torch.zeros(size = (2* self.num_layers, x.shape[1], self.hidden_dim))
        rnn_output, rnn_hidden = self.rnn(x, h0)
        hidden = torch.tanh(self.fc(torch.cat((rnn_hidden[-2,:,:], rnn_hidden[-1,:,:]), dim = 1)))

      elif self.rnn_type == "GRU":
        h0 = torch.zeros(size = (2 * self.num_layers, x.shape[1], self.hidden_dim)) # initialize the hidden state to zeros
        rnn_output, rnn_hidden = self.gru(x, h0)
        # rnn_output: shape == [seq_len, batch_size, 2*hidden_dim]
        # rnn_hidden: shape == [2*num_layers, batch_size, hidden_dim]** it is {seq_len, hidden_dim}
        hidden = torch.tanh(self.fc(torch.cat((rnn_hidden[-2,:,:], rnn_hidden[-1,:,:]), dim = 1))) # shape == [batch_size, hidden_dim]
      elif self.rnn_type == "LSTM":
        h0 = torch.zeros(size = (2 * self.num_layers, x.shape[1], self.hidden_dim))
        c0 = torch.zeros(size = (2 * self.num_layers, x.shape[1], self.hidden_dim))
        rnn_output, (rnn_hidden, rnn_cell) = self.lstm(x, (h0, c0))
        # rnn_out: shape == [seq_len, batch_size, 2 * hidden_dim]
        # rnn_hidden: shape == [2*num_layers, batch_size, hidden_dim]
        # rnn_cell: shape == [2 * num_layers, batch_size, hidden_dim]
        hidden = torch.tanh(self.fc(torch.cat((rnn_hidden[-2, :, :], rnn_hidden[-1, :, :]), dim = 1))) # shape == [batch_size, hidden_dim]
      else:
        print(f">>>> {ArgumentTypeError} :unsupported argument for the rnn_type")
    else:
      if self.rnn_type == "RNN":
        h0 = torch.zeros(size = (self.num_layers, x.shape[1], self.hidden_dim))
        rnn_output, rnn_hidden = self.rnn(x, h0)
        hidden = torch.tanh(self.fc(rnn_hidden.view(rnn_hidden.shape[1], -1))) # shape [batch, hidden_dim * num_layers]
      elif self.rnn_type == "GRU":
        h0 = torch.randn(size = (self.num_layers, x.shape[1], self.hidden_dim))
        rnn_output, rnn_hidden = self.gru(x, h0)
        # rnn_output: shape == [seq_len, batch_size, hidden_dim]
        # rnn_hidden_dim: shape == [num_layers, batch_size, hidden_dim]
        hidden = torch.tanh(self.fc(rnn_hidden.view(rnn_hidden.shape[1], -1))) # shape == [batch_size, hidden_dim * num_layers]
      
      elif self.rnn_type == "LSTM":
        h0 = torch.randn(size = (self.num_layers, x.shape[1], self.hidden_dim))
        c0 = torch.randn(size = (self.num_layers, x.shape[1], self.hidden_dim))
        rnn_output, (rnn_hidden, rnn_cell) = self.lstm(x, (h0, c0))
        # rnn_output: shape == [seq_len, batch_size, hidden_dim]
        # rnn_hidden: shape == [num_layer, batch_size, hidden_dim]
        hidden = torch.tanh(self.fc(rnn_hidden.view(rnn_hidden.shape[1], -1))) # shape == [batch_size, num_layers * hidden_dim]
      else:
        print(f">>>> {ArgumentTypeError}: unsupported argument for th rnn_type")
    return rnn_output, hidden



### Testing the Encoder's network if its produces the desired outputs ###

input_ = torch.randn(size = (32, 30))
rnn_type = ["RNN", "GRU", "LSTM"]
for rnn in rnn_type:
  rnn_surv = Encoder_RNN4Surv(input_dim = 30,
                    hidden_dim = 256,
                    num_layers = 2,
                    seq_len = 10,
                    rnn_type = rnn_type[0],
                    bidirectional = True)
  if rnn == "RNN":
    out_, hidden_ = rnn_surv(input_)
    print(f">>>> The rnn output: {out_.shape}, The rnn hidden state: {hidden_.shape}")
  elif rnn == "GRU":
    out_, hidden_ = rnn_surv(input_)
    print(f">>>> The GRU output: {out_.shape}, The GRU hidden state: {hidden_.shape}")
  else:
    out_, hidden_ = rnn_surv(input_)
    print(f">>>> The LSTM output: {out_.shape}, The LSTM hidden state: {hidden_.shape}")

